<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Golang的strings.go源码解析 - Rabin-Karp了解一下？]]></title>
    <url>%2F2019%2F06%2F20%2Fgolang%2Fsource-code%2Fstrings-go-source-code%2F</url>
    <content type="text"><![CDATA[strings包是我们经常在处理字符串的时候要用的，这次我们来看看它其中的一些方法具体是如何实现的。我就找到其中常用的几个方法，然后针对其中比较难的部分还有应用到一些特别算法的部分进行分析。 ToUpper先来看个简单的ToUpper，将所有字符转换成大写。这个如果让我们自己实现也没有什么难度，就是遍历每个字符转换成大写就可以。 12345678910111213141516171819202122232425262728// ToUpper returns a copy of the string s with all Unicode letters mapped to their upper case.func ToUpper(s string) string &#123; isASCII, hasLower := true, false for i := 0; i &lt; len(s); i++ &#123; c := s[i] if c &gt;= utf8.RuneSelf &#123; isASCII = false break &#125; hasLower = hasLower || (c &gt;= 'a' &amp;&amp; c &lt;= 'z') &#125; if isASCII &#123; // optimize for ASCII-only strings. if !hasLower &#123; return s &#125; b := make([]byte, len(s)) for i := 0; i &lt; len(s); i++ &#123; c := s[i] if c &gt;= 'a' &amp;&amp; c &lt;= 'z' &#123; c -= 'a' - 'A' &#125; b[i] = c &#125; return string(b) &#125; return Map(unicode.ToUpper, s)&#125; 可以看到，源码中考虑的比较周全，判断了一下字符集的问题。 小技巧c -= ‘a’ - ‘A’我们可以看到，这个转换大写的技巧，学习一下。如果转换成小写，只要改成+就可以了。 Replace然后看一个稍微复杂一些的，Replace，这个函数的目标是替换s中old的字符，替换前n个，如果n为负数则全部替换。作为实现也其实不难，就是找到对应字符替换就可以。 123456789101112131415161718192021222324252627282930313233343536373839// Replace returns a copy of the string s with the first n// non-overlapping instances of old replaced by new.// If old is empty, it matches at the beginning of the string// and after each UTF-8 sequence, yielding up to k+1 replacements// for a k-rune string.// If n &lt; 0, there is no limit on the number of replacements.func Replace(s, old, new string, n int) string &#123; if old == new || n == 0 &#123; return s // avoid allocation &#125; // Compute number of replacements. if m := Count(s, old); m == 0 &#123; return s // avoid allocation &#125; else if n &lt; 0 || m &lt; n &#123; n = m &#125; // Apply replacements to buffer. t := make([]byte, len(s)+n*(len(new)-len(old))) w := 0 start := 0 for i := 0; i &lt; n; i++ &#123; j := start if len(old) == 0 &#123; if i &gt; 0 &#123; _, wid := utf8.DecodeRuneInString(s[start:]) j += wid &#125; &#125; else &#123; j += Index(s[start:], old) &#125; w += copy(t[w:], s[start:j]) w += copy(t[w:], new) start = j + len(old) &#125; w += copy(t[w:], s[start:]) return string(t[0:w])&#125; 其实核心就是下面三句w += copy(t[w:], s[start:j])w += copy(t[w:], new)start = j + len(old)利用一个start去标记从旧字符串的那个位置开始复制，到目标字符处，然后复制需要替换的字符进去就可以了，最后移动start为了下一次准备就可以了。 小技巧t := make([]byte, len(s)+n*(len(new)-len(old)))这个在源码中很是常见，告诉我们一个道理，在创建slice的时候，尽可能的去指定好你需要的长度来避免扩容。 Index好了，热身差不多了，来看我们这次的重头戏，index。我们经常需要确定一个字符串是否存在于另一个字符串内，并且要知道它的位置，所以需要index方法。其实说到底就是字符串匹配嘛。 自己思考一般看源码我都习惯先自己想想怎么去实现，这个方法对于我来说很熟悉，在java中其实很暴力，就是两层for搞定，先找到第一个一样的字符，然后匹配剩下的。然后我也知道，字符串匹配在算法中有著名的KMP算法，但是理解难度很大。不知道golang会怎么实现，于是我看到了一个新的算法RabinKarp（我之前不了解） 源码1234567891011121314151617181920212223func indexRabinKarp(s, substr string) int &#123; // Rabin-Karp search hashss, pow := hashStr(substr) n := len(substr) var h uint32 for i := 0; i &lt; n; i++ &#123; h = h*primeRK + uint32(s[i]) &#125; if h == hashss &amp;&amp; s[:n] == substr &#123; return 0 &#125; for i := n; i &lt; len(s); &#123; h *= primeRK h += uint32(s[i]) h -= pow * uint32(s[i-n]) i++ if h == hashss &amp;&amp; s[i-n:i] == substr &#123; return i - n &#125; &#125; return -1&#125; 你先自己尝试看看是否能看出什么门道？ 猜测是不是乍看之下这个方法很复杂，各种操作眼花缭乱，如果你是第一次看源码可能是这样的，看多了你应该有和我一样的直觉和经验（反正我是有感觉）我看源码的第二个步骤就是大致看一眼，然后在不看任何文章解析的情况下猜测它的实现。在我看完上面之后留个我三个重点 hashss, pow := hashStr(substr) h += uint32(s[i]) h -= pow * uint32(s[i-n]) if h == hashss &amp;&amp; s[i-n:i] == substr { 它获取了对应的hash值，这个算法和hash有关 它对哈希值进行了增减操作 它比较哈希值和字符串从而确定位置 到这里，我已经有了一个大概的思路，这个算法应该是通过哈希值快速确定子串是否可能存在，在哈希值相同的情况下再去比较真实的字符是否一致，同时在计算哈希值的时候采用特殊的机制来实现了增加就可以完成哈希的改变。其实如果你有相同的想法，恭喜你，已经八九不离十了。 分析我们举个实际的例子来说明上面的事情原本的字符串为：”ABCDE”，子串为”BCD”首先计算出”BCD”的hash为100（举个例子）然后循环原本的字符串取出”ABC”计算hash为200 != 100所以一定不是取出字符D原来的hash加D减去A计算hash为100 == 100（这里注意，不是重新计算，而是在原有的基础上进行的计算）最后还是要比较一遍是否正确，因为hash一致不一定原值一致。 假设待匹配字符串的长度为M，目标字符串的长度为N，那么一共比较N-M+1就可以了 hash那么其实你应该注意到了，最神奇的就是这个hash值，为什么可以这样操作，如果是md5这种必须重新计算，是不可能完成这样的操作的。 12345678910111213141516171819// primeRK is the prime base used in Rabin-Karp algorithm.const primeRK = 16777619// hashStr returns the hash and the appropriate multiplicative// factor for use in Rabin-Karp algorithm.func hashStr(sep string) (uint32, uint32) &#123; hash := uint32(0) for i := 0; i &lt; len(sep); i++ &#123; hash = hash*primeRK + uint32(sep[i]) &#125; var pow, sq uint32 = 1, primeRK for i := len(sep); i &gt; 0; i &gt;&gt;= 1 &#123; if i&amp;1 != 0 &#123; pow *= sq &#125; sq *= sq &#125; return hash, pow&#125; 这个就是hash算法，其实它每次完成的就是 *primeRK 加上新的字符，那么pow是什么呢？加减究竟是如何完成的呢？我举个例子你就明白了。 还是刚才的ABCDE和BCD，我们用q表示常数primeRK那么BCD的hash计算出来应该是B q^2 + C q + D而ABC的hash应该是A q^2 + B q + C那当D来的时候如何操作的呢？回看一下indexRabinKarp就明白了。[A q^2 + B q + C] q + D - A pow= A q^3 - A pow + B q^2 + C q + D明白了吧，这个pow其实就是计算hash值时的最高指数，通过每次减去常数的最高指数项就能完成之前的操作。 聪明。不由得佩服能想出这样算法的人~ 其他一些方法看完最复杂的index实现，再说说几个由它引申出来的方法。 genSplit其实就是分组字符串，通过某些子串去分割成一个个部分，其实实现就是每次Index找到位置然后进行存储到新的地方就可以了。123456789for i &lt; n &#123; m := Index(s, sep) if m &lt; 0 &#123; break &#125; a[i] = s[:m+sepSave] s = s[m+len(sep):] i++&#125; countGeneric计数，统计字符串中子串出现的数目，也是通过index完成，统计一下而已12345678for &#123; i := Index(s, substr) if i == -1 &#123; return n &#125; n++ s = s[i+len(substr):]&#125; 总结其实很多源码中的实现不复杂，多看看，不仅能熟练使用api还能学到一些骚操作，何乐而不为呢？不得不佩服一些牛逼的算法实现，真的厉害~]]></content>
      <categories>
        <category>golang源码解析</category>
      </categories>
      <tags>
        <tag>strings</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang的slice]]></title>
    <url>%2F2019%2F06%2F18%2Fgolang%2Fsource-code%2Fslice-source-code-review%2F</url>
    <content type="text"><![CDATA[今天来说个简单的，也不简单的东西，那就是切片。slice对于golang来说那真的是一个非常常用的东西了，很多地方都会用到它，今天就来说说，slice底层是如何实现的，又有哪些坑是需要提前注意的。 slice结构很多第一次接触golang的同学都会认为，数组和切片是差不多的东西，其实不是的，切片是数组的封装。12345type slice struct &#123; array unsafe.Pointer len int cap int&#125; 上面这个就是slice的结构，顺便说一下：slice的源码位置是：go/src/runtime/slice.go 其中array是一个指针，指向底层的数组 len代表slice的长度 cap代表slice的容量 为什么会有长度和容量这个区分呢，这两个东西是用来干什么的呢？我们往下看。 slice的长度和容量我们先来看一个最简单的案例1234sli := make([]int, 2)fmt.Printf("len=%d cap=%d\n", len(sli), cap(sli))sli = append(sli, 1)fmt.Printf("len=%d cap=%d\n", len(sli), cap(sli)) 我们创建一个长度为2的slice然后打印一下它的len和cap。然后添加一个元素，再次打印最后结果为：len=2 cap=2len=3 cap=4 从中我们可以知道len和cap是不同的东西，明显嘛。但是为什么呢？ 其实原因很简单，因为数组在创建的时候只能创建固定大小的数组，而当slice在不断往其中添加元素的时候，势必会遇到大小不够的情况，如果每次添加都不够，那么每次都要创建新的数组，那会相当浪费时间和资源，所以当不够的时候索性一次就创建大一些，所以cap其实就代表了整体的一个容量，而len代表当前用到了第几个。 slice的扩容刚才提到的整个过程就是扩容的原因，那么slice究竟是如何进行扩容的呢？网上我看见过两个说法： 每次2倍 当len&lt;1024的时候每次2倍，当len&gt;1024的时候每次1.25倍 我最后得到的结论是其实两个都不完全正确。正确的应该看看源码中是怎么说的。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051func growslice(et *_type, old slice, cap int) slice &#123; ..... newcap := old.cap doublecap := newcap + newcap if cap &gt; doublecap &#123; newcap = cap &#125; else &#123; if old.len &lt; 1024 &#123; newcap = doublecap &#125; else &#123; // Check 0 &lt; newcap to detect overflow // and prevent an infinite loop. for 0 &lt; newcap &amp;&amp; newcap &lt; cap &#123; newcap += newcap / 4 &#125; // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap &lt;= 0 &#123; newcap = cap &#125; &#125; &#125; var overflow bool var lenmem, newlenmem, capmem uintptr const ptrSize = unsafe.Sizeof((*byte)(nil)) switch et.size &#123; case 1: lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) &gt; _MaxMem newcap = int(capmem) case ptrSize: lenmem = uintptr(old.len) * ptrSize newlenmem = uintptr(cap) * ptrSize capmem = roundupsize(uintptr(newcap) * ptrSize) overflow = uintptr(newcap) &gt; _MaxMem/ptrSize newcap = int(capmem / ptrSize) default: lenmem = uintptr(old.len) * et.size newlenmem = uintptr(cap) * et.size capmem = roundupsize(uintptr(newcap) * et.size) overflow = uintptr(newcap) &gt; maxSliceCap(et.size) newcap = int(capmem / et.size) &#125; ...... return slice&#123;p, old.len, newcap&#125;&#125; 我们省略其中部分代码看关键部分，首先说明一下growslice这个方法是扩容的方法，其中的入参et *_type, old slice, cap int分别是元素的类型，老的slice，新slice要求的最小容量针对最后这个参数举个简单的例子，当前如果是len=2，cap=2的一个slice添加一个元素，那么这个参数传入的就是3，因为最小需要容量为3。 其实从前半部分来看，第二种说法是正确的，当len&lt;1024确实就是两倍，而当len&gt;1024的时候，每次以原来的25%增加直到满足要求。 但是其实你看后面部分，有一个roundupsize的方法，并且又对newcap进行赋值，所以肯定修改了cap的值，所以其实扩容并没有描述的那么简单，实际中会进行内存对齐，具体什么事内存对齐呢？简单的描述是，内存中肯定不是你想怎么放就怎么放的肯定要满足一个规则，有的地方虽然你只要这么点地方，但是由于美观的要求，会多给你一点，凑个整，保持统一整齐，这就是内存对齐。（是不是花里胡哨的，我尽可能已经白话了，具体还是要看https://blog.csdn.net/u011957758/article/details/85059117）总之，我们知道，slice的扩容并不是那么简单的。最后附上一个例子作为验证：123456789101112func main() &#123; sli := make([]int, 2) preCap := cap(sli) for i := 0; i &lt;= 2048; i++ &#123; sli = append(sli, i) if cap(sli) != preCap &#123; fmt.Printf("len=%4d \t cap=%d\n", len(sli)-1, cap(sli)) preCap = cap(sli) &#125; &#125;&#125; 输出123456789101112len= 2 cap=4len= 4 cap=8len= 8 cap=16len= 16 cap=32len= 32 cap=64len= 64 cap=128len= 128 cap=256len= 256 cap=512len= 512 cap=1024len=1024 cap=1280len=1280 cap=1696len=1696 cap=2304 1280 = 1024 1.251696 = 1280 1.325 slice的操作普通的创建添加元素我就不多说了，你肯定知道，你要是不知道就不会来看我的博客了。说一些看起来高端的微操。 创建slicemake([]int, 10, 32)make的时候可以指定第三个参数也就是初始的cap slice删除一个元素sli = append(sli[:3], sli[4:]…)因为底层是数组，所以删除一个元素看起来会比较麻烦 reslice123456789101112func main() &#123; sli := make([]int, 0) for i := 1; i &lt;= 10; i++ &#123; sli = append(sli, i) &#125; fmt.Println(sli) sli = sli[1:3:5] fmt.Println(sli) fmt.Println(len(sli), cap(sli))&#125; sli = sli[1:3:5]reslice的时候也可以指定cap，但是注意的是，这个时候并不是指定的整体容量为5，而是容量为原来slice下标为5的地方。如果原来是[1 2 3 4 5 6 7 8 9 10]按照上面的操作，按照我自己的平常说的就是切两刀，第一刀是切到3，第二刀是切到5slice是[2,3]，但是实际底层还有[4,5] cap应该是4，所以输出应该是： 123[1 2 3 4 5 6 7 8 9 10][2 3]2 4 slice的坑点slice的坑其实主要在于使用者需要清楚值传递引用传递的关系。首先在golang中只有值传递，没有引用传递。 reslice的时候要注意，如果只是reslice那么后续操作是会对原来的slice造成影响的。 但是如果经过append之后，那么由于扩容的时候回重新分配内存，如果涉及扩容之后，那么就不会对原来的slice造成影响。 如果作为函数的参数传递的是数组，因为是值传递，所以函数内部的修改不会对外部的变量产生影响，但是如果是slice传递，那么因为传递的是指针，所以会修改外部的变量。 同时因为是值传递，形参的重新赋值是不会对外部的变量造成影响的。 下面的代码说明了以上可能出现的坑点1234567891011121314151617181920212223242526272829303132333435363738package mainimport "fmt"func main() &#123; a := [3]int&#123;1, 1, 1&#125; s := []int&#123;1, 1, 1&#125; modifyArray(a) fmt.Println(a) modifySlice(s) fmt.Println(s) reslice(s) fmt.Println(s) s1 := make([]int, 2, 3) s2 := append(s1, 1) s2[0] = 3 fmt.Println(s1) s3 := append(s1, 1, 1) s3[0] = 4 fmt.Println(s1)&#125;func modifyArray(a [3]int) &#123; a[0] = 2&#125;func modifySlice(s []int) &#123; s[0] = 2&#125;func reslice(s []int) &#123; s = s[:2]&#125; 总结总结一下，创建slice的时候如果可以的话尽可能初始化好要用容量，以免经常扩容。slice作为参数进行传递的时候，还有slice进行append的时候注意一下，别的应该没有问题。总的来说slice的实现还是比较简单的。]]></content>
      <categories>
        <category>golang源码解析</category>
      </categories>
      <tags>
        <tag>slice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅入深出ETCD之【集群部署与golang客户端使用】]]></title>
    <url>%2F2019%2F06%2F14%2Fgolang%2Fopen-source-component%2Fetcd-cluster-client%2F</url>
    <content type="text"><![CDATA[之前说了etcd的简介，命令行使用，一些基本原理。这次来说说现实一点的集群部署和golang版本的客户端使用。因为在实际使用过程中，etcd的节点肯定是需要2N+1个进行部署的，所以有必要说明一下集群的部署。 集群部署网上有很多集群部署的教程，有的很复杂，其实对于我们实际使用来说，其实配置并不复杂，下面举例一种最简单的集群配置。（简单到你想不到~） 下载https://github.com/etcd-io/etcd/releases还是在github上面找到需要下载的版本我使用的是etcd-v3.3.13-linux-amd64.tar.gz使用wget下载到linux你喜欢的目录，或者本地下载完成之后上传均可。 部署首先我找了三台机器，对应ip为192.168.4.224192.168.4.225192.168.4.226PS：提醒一下记得开发对应防火墙的端口 然后将下载的文件解压，之后进入解压后的目录，分别使用下面的命令启动。(注意下面的命令对应的是三台不同的机器，你需要修改对应为你自己的ip) 1234567891011121314151617181920212223$ ./etcd --name infra0 --initial-advertise-peer-urls http://192.168.4.224:2380 \--listen-peer-urls http://192.168.4.224:2380 \--listen-client-urls http://192.168.4.224:2379,http://127.0.0.1:2379 \--advertise-client-urls http://192.168.4.224:2379 \--initial-cluster-token etcd-cluster-1 \--initial-cluster infra0=http://192.168.4.224:2380,infra1=http://192.168.4.225:2380,infra2=http://192.168.4.226:2380 \--initial-cluster-state new$ ./etcd --name infra1 --initial-advertise-peer-urls http://192.168.4.225:2380 \--listen-peer-urls http://192.168.4.225:2380 \--listen-client-urls http://192.168.4.225:2379,http://127.0.0.1:2379 \--advertise-client-urls http://192.168.4.225:2379 \--initial-cluster-token etcd-cluster-1 \--initial-cluster infra0=http://192.168.4.224:2380,infra1=http://192.168.4.225:2380,infra2=http://192.168.4.226:2380 \--initial-cluster-state new$ ./etcd --name infra2 --initial-advertise-peer-urls http://192.168.4.226:2380 \--listen-peer-urls http://192.168.4.226:2380 \--listen-client-urls http://192.168.4.226:2379,http://127.0.0.1:2379 \--advertise-client-urls http://192.168.4.226:2379 \--initial-cluster-token etcd-cluster-1 \--initial-cluster infra0=http://192.168.4.224:2380,infra1=http://192.168.4.225:2380,infra2=http://192.168.4.226:2380 \--initial-cluster-state new 至此，三个节点的集群部署完成。😂😂😂没错就是这么easy，没有网上说的那么复杂。 配置文件如果你嫌弃每次使用这么长的命令进行启动，你可以将它写为配置文件：12345678910111213141516171819202122# 当前节点名称name: infra1# etcd数据保存目录data-dir: /usr/local/etcd# 供外部客户端使用的urllisten-client-urls: http://192.168.4.225:2379,http://127.0.0.1:2379# 广播给外部客户端使用的urladvertise-client-urls: http://192.168.4.225:2379# 集群内部通信使用的URLlisten-peer-urls: http://192.168.4.225:2380# 广播给集群内其他成员访问的URLinitial-advertise-peer-urls: http://192.168.4.225:2380# 集群的名称initial-cluster-token: etcd-cluster-1# 初始集群成员列表initial-cluster: infra0=http://192.168.4.224:2380,infra1=http://192.168.4.225:2380,infra2=http://192.168.4.226:2380#初始集群状态initial-cluster-state: new 然后指定配置文件的路径进行启动就可以了1./etcd --config-file=conf.yml 其他部署策略以上的部署一方面，我个人部署时使用的最简单方式，更简单的可能是使用yum进行etcd的下载。当然上述方式也存在一些问题，现在的etcd相当于裸奔的情况： 没有鉴权就想到于任何人知道ip和端口就可以连接上你的etcd，所以当前可能只适用于内网使用，服务通过内网ip进行访问（这个可以通过添加权限和用户来完成） 当前通信是没有加密的 当前etcd是利用静态ip来进行配置的，我认为这也是实际中用到最普通的情况，但是etcd还提供发现机制来进行部署和配置，更加灵活 等等，这些部署策略更多针对于线上，因为官方写的非常详细了，我感觉再写也就班门弄斧了。https://doczhcn.gitbook.io/etcd/index/index-1/clustering Golang客户端使用这里来实际用代码操作一下etcd，还是和之前使用命令行一样，get/put/del/watch/lease用一下这些操作，其他操作请查看dochttps://godoc.org/github.com/coreos/etcd/clientv3 客户端下载这里不建议使用go get进行下载，真的太慢了，可以直接从github上面下载之后放到对应目录快一些。https://github.com/etcd-io/etcd下载解压之后放到gopath下对应：go/src/go.etcd.io/etcd 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package mainimport ( "context" "fmt" "go.etcd.io/etcd/clientv3" "go.etcd.io/etcd/mvcc/mvccpb" "time")func main() &#123; // 配置客户端连接 client, err := clientv3.New(clientv3.Config&#123; // Endpoints: []string&#123;"127.0.0.1:2379"&#125;, Endpoints: []string&#123;"192.168.4.224:2379", "192.168.4.225:2379", "192.168.4.226:2379"&#125;, DialTimeout: 5 * time.Second, &#125;) if err != nil &#123; panic(err) &#125; defer client.Close() // 启动watch监听 watch := client.Watch(context.TODO(), "aaa") go func() &#123; for &#123; watchResponse := &lt;- watch for _, ev := range watchResponse.Events &#123; switch ev.Type &#123; case mvccpb.DELETE: fmt.Printf("监听到del：%s\n", ev.Kv.Key) case mvccpb.PUT: fmt.Printf("监听到put：%s, %s\n", ev.Kv.Key, ev.Kv.Value) &#125; &#125; &#125; &#125;() // 新增 putResponse, err := client.Put(context.TODO(), "aaa", "xxx") if err != nil &#123; fmt.Println(err) return &#125; fmt.Println(putResponse.Header.String()) // 查询 getResponse, err := client.Get(context.TODO(), "aaa") if err != nil &#123; fmt.Println(err) return &#125; fmt.Println(getResponse.Kvs) // 删除 deleteResponse, err := client.Delete(context.TODO(), "aaa") if err != nil &#123; fmt.Println(err) return &#125; fmt.Println(deleteResponse.Header.String()) // 申请租约 grantResponse, err := client.Grant(context.TODO(), 10) if err != nil &#123; fmt.Println(err) return &#125; // 使用租约 response, err := client.Put(context.TODO(), "aaa", "xxx", clientv3.WithLease(grantResponse.ID)) if err != nil &#123; fmt.Println(err) return &#125; fmt.Println(response.Header.String()) // 等待租约自动过期 time.Sleep(time.Second * 20)&#125; 大致能得到以下输出 监听到put：aaa, xxxcluster_id:14841639068965178418 member_id:10276657743932975437 revision:53 raft_term:4[key:”aaa” create_revision:53 mod_revision:53 version:1 value:”xxx” ]监听到del：aaacluster_id:14841639068965178418 member_id:10276657743932975437 revision:54 raft_term:4监听到put：aaa, xxxcluster_id:14841639068965178418 member_id:10276657743932975437 revision:55 raft_term:4监听到del：aaa 其实使用起来还是非常简单，我就不过多赘述了。]]></content>
      <categories>
        <category>etcd</category>
      </categories>
      <tags>
        <tag>etcd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅入深出ETCD之【raft原理】]]></title>
    <url>%2F2019%2F06%2F12%2Fgolang%2Fopen-source-component%2Fetcd-raft%2F</url>
    <content type="text"><![CDATA[这次我们来说说，有关于etcd原理的一些事情。之前我们已经了解到了etcd是一个分布式的k-v存储，那么它究竟是如何保证数据是如何复制到每个节点上面去的呢？又是如何保证在网络分区的情况下能正常工作下去？raft协议到底是什么？带着这些问题我们继续往下看。 raft选举策略我们知道etcd使用raft协议来保证整个分布式的节点网络能正常的运转并且能正确的将数据复制到每个节点上面去。那么什么是raft协议嘞？ 首先我们有这样一个背景：raft是想维护整一个网络，其中有一个领导人，这个领导人负责将收到的信息同步给网络中的其他所有节点，从而保证整个网络数据一致。 如果你有一定的英文基础，我建议直接查看下面这个网站，它用动画非常清楚的描述了raft选举的整个过程：http://thesecretlivesofdata.com/raft/ 这个其实已经说明的超级棒了，如果你还看不懂，我下面会用最简单的几个要点来进行最简单的说明。 大多数理论首先说明一个理论，叫做大多数理论，很简单，举个栗子： 有10个人，如果你将苹果给其中的6个人（大多数），那么你随机选择5个人，一定有一个人会有苹果。 在etcd中的应用： 选举中只要有大多数（超过半数的人给你投票）你肯定就是票数最多的了，不可能有人比你更多。 只需要将日志复制给大多数的节点，那么只要有一半的节点正常工作就能保证数据最新 选举状态下面是一些选举过程中节点的状态leader 表示选举最终产生的领导人candidate 候选状态，表示当前正在参与选举follower 表示选举最终自己不是领导人，那自己就是从属节点 选举过程与要点 所有节点一开始都是follower状态 当节点处于follower状态时，每个节点随机经过一段时间，如果没有收到leader的消息就会进入candidate状态（证明当前没有leader节点需要重新进行选举），如果收到信息就会继续保持follower状态 当节点处于candidate就会要求别人给自己投票，收到大多数的节点的投票那就转变为leader状态，否则要么是别的节点成为了leader，要么就是因为特殊情况导致这次选举失败重新进行选举 每次选举举办的时候有一个term，在每一个term中，每个节点只能投票一次 投票的时候必须投给当前数据至少和自己一样的节点，并且term大的优先 日志复制规则etcd是通过日志复制来实现数据同步的这个图网上也很多，说明的是日志复制的规则每个节点都有一份自己的日志，有的节点多，有的节点少，日志最多的肯定是leader。上图还有几个要点，我看别人没提到，我就提一下： 颜色代表term 第四行表示的这个节点，第一term下复制了两个日志就异常挂掉了 最终只有第三行这个follower和第一行的leader保持了同步 异常情况raft之所以厉害因为即使出现一些特殊情况，整个网络在一定的时间之后也能自动恢复并正常工作。 一个节点的异常首先最常见的情况就是一个节点出现异常，有可能是这个节点的服务器挂了，或者别的什么原因。 如果出现问题的这个节点是follower，那么没有关系，整个网络依旧能正常运行，当这个节点再次加入网络的时候也只需要同步后面的数据即可。 如果出现问题的是leader，有一点麻烦，因为网络中没有leader节点了，那么就会重新进行选举，重新找一个leader，当这个异常节点恢复之后发现当前网络中有leader了，而且term还比自己大，那么自己就退位称为follower。 网络分区还有一种异常情况是由于网络导致的，网络出现异常，导致节点之间的通信存在异常，一部分节点与另一部分之间没有办法访问了。如下图所示： 上面三个follower没有办法与下面的节点进行通信。 当客户端再次请求leader发送数据的时候，leader发现没有办法将数据同步给给大多数节点，它只能给自己和旁边的一个，此时leader没有办法给客户端反馈。 上面三个节点由于收不到leader的消息，那么会认为网络中没有leader存在，会重新进行选举操作，因为当前上面有三个节点存在（只要有超过半数的节点参与选举就行），所以可以重新选举成功，选出新的leader告诉客户端，客户端就会重新发送数据到新的leader。 当网络恢复之后又会找到最新的leader从而将数据同步至最新的状态。 总结总的来说，只要整个网络中存在大多数节点正常运行，那么etcd就是可用的，并且能够保证数据正确。当网络恢复之后也能将数据调整到最新的状态。raft强大的地方在于它能自动的进行状态的变化，自动进行选举，并且选举遵循一定的策略，进而保证整个网络的正常运转。同时保证数据的一致性。了解etcd的这个原理有助于我们后续的使用以及源码的阅读。]]></content>
      <categories>
        <category>etcd</category>
      </categories>
      <tags>
        <tag>etcd</tag>
        <tag>raft</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅入深出ETCD之【简介与命令行使用】]]></title>
    <url>%2F2019%2F06%2F10%2Fgolang%2Fopen-source-component%2Fetcd-brief%2F</url>
    <content type="text"><![CDATA[你知道etcd吗？随着k8s的使用广泛之后，etcd被非常多的人所知道，同时又因为它可靠的分布式特性被很多人喜欢。所以，我准备有几篇博文来记录一下，从基本使用到线上部署再到原理分析，做一个系列。那么，今天先来说说它的简介与命令行的使用。 简介ETCD是什么我个人总结为下面用几个要点： 高可用K-V存储，就类似于redis一样的键值对存储。 允许应用实时监听存储中的K-V变化。 能够容忍单点故障，能够应对网络分区。 etcd利用raft在集群中同步K-V信息，raft是强一致的集群日志同步算法。 总结：etcd是一个分布式高可用k-v存储，通过复制达到每个节点存储的信息一致，从而保证高可用。 数据复制这里简单说一下复制的具体流程： （client为我们的客户端，用来发出存储请求，leader和follower都是etcd的节点）就如图上所看到的，我叫它两段式提交： 客户端请求leader发送存储的数据，然后leader节点要将信息通过日志复制给大多数的follower节点，如上图所示，只需要复制给两个（加上它自己是三个）那么就是大多数节点。 leader当复制完成之后才会本地提交，然后返回给客户端成功，（如果没有或者不能复制给大多数节点，那么则存储失败）此时再同时其他follower去他们自己本地提交。是不是有一种分布式事务的感觉？分布式的解决通常都是这种感觉。 我们也可以看到，etcd通过先将数据存放在大多数节点上面从而保证数据不会出错并且效率较高，最终所有节点数据还是会同步一致的。 官方给出写入的性能：1000/s PS:这里因为是简介，所以就简单提一下，有关如何选举出leader还有raft协议的一些具体细节，以及当出现网络分区或者节点异常问题的恢复会在之后的博客中给出。 存储结构底层存储key是有序排列的‘key’ -&gt; ‘value’ aaa/bbb -&gt; 111aaa/bbc -&gt; 3333bbb/aaa -&gt; 1321ccc -&gt; 24就是按照key的顺序依次排列，相同前缀的key会被放在一起，这样到存储结构，当查询时可以通过key的前缀将一系列的value都取出来 watch机制和lease租约etcd有一个很棒的机制要单独提一句，就是watch，它允许你去监控一个key的变化。当你监控了之后，这个key的添加修改删除都会被监控到。lease租约，这个机制和redis中的key过期机制一样，可以申请一个租约，这个租约有一个时间限制，比如60秒，你可以将这个租约设置到一个key上，那么这个key过60秒就会被自动删除。当然也可以进行续租。 具体使用情况，可以从后面的命令行操作中看到。 还有一些小点 etcd使用grpc，所以网络性能会高 部署节点数量要求是2N+1个 选举leader需要半数以上的节点参与 etcd是支持事务操作的，可以if第一次a提交正常，then提交b，else不提交b 本地单节点部署我们一开始学习和测试的时候只需要在本地部署一个单节点就可以了，单节点的部署比较方便这边简单说明一下。首先下载对应的版本：https://github.com/etcd-io/etcd/releases我这边使用的mac对应的darwin-amd64的版本，其他版本应该类似。下载解压之后有两个文件比较重要： etcd 这个是节点 etcdctl 这个是客户端进入所在目录使用命令进行启动和使用 使用节点命令1➜ ./etcd 使用客户端命令1234567➜ ./etcdctlNAME: etcdctl - A simple command line client for etcd.WARNING: Environment variable ETCDCTL_API is not set; defaults to etcdctl v2. Set environment variable ETCDCTL_API=3 to use v3 API or ETCDCTL_API=2 to use v2 API. 之后会出现上述类似警告，告诉你，默认使用的是v2版本的API，你需要设置环境变量ETCDCTL_API=3就能使用v3版本的API了，这里我们使用命令export ETCDCTL_API=3 或者你可以手动修改环境变量添加export ETCDCTL_API=3就可以了，当不出现警告的时候证明环境变量设置正确。 简单命令行操作下面介绍几个最基本的etcd的操作，其实非常简单。主要与redis不同的是拥有独特的watch机制，这个机制非常棒。 put1234➜ ./etcdctl put /aaa/a 1OK➜ ./etcdctl put /aaa/b 2OK get12345678➜ ./etcdctl get /aaa/a/aaa/a1➜ ./etcdctl get --prefix /aaa/aaa/a1/aaa/b2 –prefix意思是取出所有前缀为/aaa的key watch新开一个窗口使用命令watch进行监听1➜ ./etcdctl watch /aaa/a 然后对/aaa/a这个key的操作全部都会被监听到1234➜ ./etcdctl put /aaa/a 123OK➜ ./etcdctl del /aaa/a1 123456➜ ./etcdctl watch /aaa/aPUT/aaa/a123DELETE/aaa/a lease创建一个60s的租约12➜ ./etcdctl lease grant 60lease 694d6b2b7d7e6a0c granted with TTL(60s) 12➜ ./etcdctl put /aaa/a 123 --lease=694d6b2b7d7e6a0cOK put的时候使用租约注意，这里需要输入上面租约的16进制标识符然后监听的地方会发现，60秒后，/aaa/a这个key被自动删除了 当然你可以使用keep-alive进行续租，如：1➜ ./etcdctl lease keep-alive 694d6b2ac4a35625 总结以上简单说明了etcd的一些基本信息，单节点部署，以及一些基本用法，从上述信息我们总结可知： etcd是分布式的，能保证在单点故障下也能正常使用 分布式也会导致问题，etcd写入性能相较redis肯定有所不及 etcd独特的watch机制可以用于很多场景，如配置更新分发等 那这里就说这么多，看完你就应该大致知道etcd是个啥玩意了，从现在看来你可能还没有感觉它有什么厉害的地方，后面我们结合实际的场景使用就能更加明白了。]]></content>
      <categories>
        <category>etcd</category>
      </categories>
      <tags>
        <tag>etcd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang指针与unsafe]]></title>
    <url>%2F2019%2F06%2F06%2Fgolang%2Fsource-code%2Fpoint-unsafe%2F</url>
    <content type="text"><![CDATA[我们知道在golang中是存在指针这个概念的。对于指针很多人有点忌惮（可能是因为之前学习过C语言），因为它会导致很多异常的问题。但是很多人学习之后发现，golang中的指针很简单，没有C那么复杂。所以今天就详细来说说指针。 指针的使用123a := 1p := &amp;afmt.Println(p) 输出：0xc42001c070 可以看到p就是一个指针，也可以说是a的地址。 1234a := 1var p *intp = &amp;afmt.Println(p) 或者也可以写成这样，因为我知道，在很多人看来，看到*号才是指针（手动滑稽） 123a := 1p := &amp;afmt.Println(*p) 输出：1 然后使用就直接通过*号就能去到对应的值了，就这么简单 指针的限制Golang中指针之所以看起来很简单，是因为指针的功能不多。我们能看到的功能就是指针的指向一个地址而已，然后对于这个地址也只能进行传递，或者通过这个的地址去访问值。 不能像C语言中一样p++，这样移动操作指针，因为其实这样操作确实不安全，很容易访问到奇怪的区域。 不同类型的指针不能相互赋值、转换、比较。会出现cannot use &amp;a (type int) as type float32 in assignment类似这样的错误 如果只是单纯说go中指针的功能，上面就已经说完了，没必要写博客，但是其实go中还有一个包叫unsafe，有了它，指针就可以像C一样想干嘛干嘛了。 unsafe三个类型其实指针有三种：一种是我们常见的*，用*去表示的指针；一种是unsafe.Pointer，Pointer是unsafe包下的一个类型；最后一种是uintptr，uintptr就厉害了，这玩意是可以进行运算的也就是可以++–； 他们之间有这样的转换关系：* &lt;=&gt; unsafe.Pointer &lt;=&gt; uintptr 有一点要注意的是，uintptr 并没有指针的语义，意思就是 uintptr 所指向的对象会被 gc 无情地回收。而 unsafe.Pointer 有指针语义，可以保护它所指向的对象在“有用”的时候不会被垃圾回收。 从这样的关系你大概就可以猜到，我们使用的指针*p转换成Pointer然后转换uintptr进行运算之后再原路返回，理论上就能等同于进行了指针的运算。我们下面就来实践一下。 unsafe操作slice12345678910111213func main() &#123; s := make([]int, 10) s[1] = 2 p := &amp;s[0] fmt.Println(*p) up := uintptr(unsafe.Pointer(p)) up += unsafe.Sizeof(int(0)) // 这里可不是up++哦 p2 := (*int)(unsafe.Pointer(up)) fmt.Println(*p2)&#125; 输出：02 从代码中我们可以看到，我们首先将指针指向切片的第一个位置，然后通过转换得到uintptr，操作uintptr + 上8位（注意这里不能++因为存放的是int，下一个元素位置相隔举例int个字节），最后转换回来得到指针，取值，就能取到切片的第二个位置了。 unsafe操作struct当然有人肯定要说了，上面那个一顿操作猛如虎，不就是访问下一个位置嘛，我直接访问就行了。那下面就是厉害的来了，我们知道如果一个结构体里面定义的属性是私有的，那么这个属性是不能被外界访问到的。我们来看看下面这个操作： 123456package basictype User struct &#123; age int name string&#125; 12345678910111213141516package mainfunc main() &#123; user := &amp;basic.User&#123;&#125; fmt.Println(user) s := (*int)(unsafe.Pointer(user)) *s = 10 up := uintptr(unsafe.Pointer(user)) + unsafe.Sizeof(int(0)) namep := (*string)(unsafe.Pointer(up)) *namep = "xxx" fmt.Println(user)&#125; User是另外一个basic包中的结构体，其中的age是小写开头的，理论上来说，我们在外部没有办法修改age的值，但是经过上面这波操作之后，输出信息是：&amp;{0 }&amp;{10 xxx}也就是说成功操作到了结构体的私有属性。 顺便提一句：创建结构体会被分配一块连续的内存，结构体的地址也代表了第一个成员的地址。 下面我们来验证一下你是否已经学会了unsafe的操作，尝试不看一个小结，自己尝试一下：如何完成字符串到[]byte的转换，并且不开辟新的空间？ 字符串和byte数组转换inplace我们知道如果将字符串转换成[]byte非常方便12s := "123"a := []byte(s) 但是这样需要开辟额外的空间，那么如何实现原地的，不需要拷贝数据的转换呢？我们想一下，其实从底层的存储角度来说，string的存储规则和[]byte是一样的，也就是说，其实指针都是从某个位置开始到一段空间，中间一格一格。所以利用unsafe就可以做到。 123456789101112func main() &#123; s := "123" a := []byte(s) print("s = " , &amp;s, "\n") print("a = " , &amp;a, "\n") a2 := (*[]byte)(unsafe.Pointer(&amp;s)) print("a2 = " , a2, "\n") fmt.Println(*a2)&#125; 输出结果：s = 0xc420055f40a = 0xc420055f60a2 = 0xc420055f40[49 50 51] 我们可以看到s和a的地址是不一样的，但是s和a2的地址是一样的，并且a2已经是一个[]byte了。嘿嘿嘿~你以为这样就结束了？？？ 存在的问题其实这个转换是存在问题的，问题就在新的[]byte的Cap没有正确的初始化。我们打印一下cap看一下fmt.Println(“cap a =”, cap(a))fmt.Println(“cap a2 =”, cap(*a2))结果是：cap a = 32cap a2 = 17418400这么大的容量是要上天呢？？？ 问题的原因在src/reflect/value.go下看12345678910type StringHeader struct &#123; Data uintptr Len int&#125;type SliceHeader struct &#123; Data uintptr Len int Cap int&#125; 看到其实string没有cap而[]byte有，所以导致问题出现，也容易理解，string是没有容量扩容这个说法的，所以新的[]byte没有赋值cap所以使用了默认值。 问题解决123456789stringHeader := (*reflect.StringHeader)(unsafe.Pointer(&amp;s))bh := reflect.SliceHeader&#123; Data: stringHeader.Data, Len: stringHeader.Len, Cap: stringHeader.Len,&#125;return *(*[]byte)(unsafe.Pointer(&amp;bh)) 通过重新设置SliceHeader就可以完成 总结以上就是所有golang指针和unsafe的相关细节和使用。那么肯定有人会问这个有什么用了？ 1、没啥事你就别乱用了，别人都说unsafe不安全了。 2、源码中很多大量的使用了指针移动的操作。 如map中通过key获取value的时候： v := add(unsafe.Pointer(b), dataOffset+bucketCnt uintptr(t.keysize)+i uintptr(t.valuesize)) 通过桶的指针的偏移拿到值，具体我就不多介绍了。总之对于你看golang源码的时候会有很大帮助的。可能必要的时候你也能用到它，还是那句话，除非你知道它在干什么，否则不要用。]]></content>
      <categories>
        <category>golang源码解析</category>
      </categories>
      <tags>
        <tag>unsafe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话图解golang map源码详解]]></title>
    <url>%2F2019%2F06%2F03%2Fgolang%2Fsource-code%2Fgraphic-golang-map%2F</url>
    <content type="text"><![CDATA[网上分析golang中map的源码的博客已经非常多了，随便一搜就有，而且也非常详细，所以如果我再来写就有点画蛇添足了（而且我也写不好，手动滑稽）。但是我还是要写，略略略，这篇博客的意义在于能从几张图片，然后用我最通俗的文字，让没看过源码的人最快程度上了解golang中map是怎么样的。 当然，因为简单，所以不完美。有很多地方省略了细节问题，如果你觉得没看够，或者本来就想了解详细情况的话在文末给出了一些非常不错的博客，当然有能力还是自己去阅读源码比较靠谱。 那么下面我将从这几个方面来说明，你先记住有下面几个方向，这样可以有一个大致的思路： 基础结构：golang中的map是什么样子的，是由什么数据结构组成的？ 初始化：初始化之后map是怎么样的？ get：如何获取一个元素？ put：如何存放一个元素？ 扩容：当存放空间不够的时候扩容是怎么扩的？ 基础结构图解这个就是golang中map的结构，其实真的不复杂，我省略了其中一些和结构关系不大的字段，就只剩下这些了。 大话大话来描述一些要点： 最外面是hmap结构体，用buckets存放一些名字叫bmap的桶（数量不定，是2的指数倍） bmap是一种有8个格子的桶（一定只有8个格子），每个格子存放一对key-value bmap有一个overflow，用于连接下一个bmap（溢出桶） hmap还有oldbuckets，用于存放老数据（用于扩容时） mapextra用于存放非指针数据（用于优化存储和访问），内部的overflow和oldoverflow实际还是bmap的数组。 这就是map的结构，然后我们稍微对比总结一下。 我们常见的map如java中的map是直接拿数组，数组中直接对应出了key-value，而在golang中，做了多加中间一层，buckets；java中如果key的哈希相同会采用链表的方式连接下去，当达到一定程度会转换红黑树，golang中直接类似链表连接下去，只不过连接下去的是buckets。 源码一瞥 下面附上源码中它们的样子，方便之后你自己阅读的时候有个印象（注意源码中的样子和编译之后是不同的哟，golang会根据map存放的类型不同来搞定它们实际的样子） 那么看完结构你肯定会有疑问？为什么要多一层8个格子的bucket呢？我们怎么确定放在8个格子其中的哪个呢？带着问题往下看。 初始化源码一瞥初始化就不需要图去说明了，因为初始化之后就是产生基础的一个结构，根据map中存放的类型不同。这里主要说明一下，初始化的代码放在什么位置。我也删除了其中一些代码，大致看看就好。 123456789101112131415161718192021222324252627282930313233// makehmap_small implements Go map creation for make(map[k]v) and// make(map[k]v, hint) when hint is known to be at most bucketCnt// at compile time and the map needs to be allocated on the heap.func makemap_small() *hmap &#123; h := new(hmap) h.hash0 = fastrand() return h&#125;// makemap implements Go map creation for make(map[k]v, hint).// If the compiler has determined that the map or the first bucket// can be created on the stack, h and/or bucket may be non-nil.// If h != nil, the map can be created directly in h.// If h.buckets != nil, bucket pointed to can be used as the first bucket.func makemap(t *maptype, hint int, h *hmap) *hmap &#123; ..... // initialize Hmap if h == nil &#123; h = (*hmap)(newobject(t.hmap)) &#125; h.hash0 = fastrand() // find size parameter which will hold the requested # of elements B := uint8(0) for overLoadFactor(hint, B) &#123; B++ &#125; h.B = B ...... return h&#125; 其中需要注意一个点：“B”，还记得刚才说名字叫bmap的桶数量是不确定的吗？这个B一定程度上表示的就是桶的数量，当然不是说B是3桶的数量就是3，而是2的3次方，也就是8；当B为5，桶的数量就是32；记住这个B，后面会用到它。 其实你想嘛，初始化还能干什么，最重要的肯定就是确定一开始要有多少个桶，初始的大小还是很重要的，还有一些别的初始化哈希种子等等，问题不大。我们的重点还是要放在存/取上面。 GET图解其实从结构上面来看，我们已经可以摸到一些门道了。先自己想一下，要从一个hashmap中获取一个元素，那么一定是通过key的哈希值去定位到这个元素，那么想着这个大致方向，看下面一张流程图来详细理解golang中是如何实现的。 大话下面说明要点： 计算出key的hash 用最后的“B”位来确定在哪个桶（“B”就是前面说的那个，B为4，就有16个桶，0101用十进制表示为5，所以在5号桶） 根据key的前8位快速确定是在哪个格子（额外说明一下，在bmap中存放了每个key对应的tophash，是key的前8位） 最终还是需要比对key完整的hash是否匹配，如果匹配则获取对应value 如果都没有找到，就去下一个overflow找 总结一下：通过后B位确定桶，通过前8位确定格子，循环遍历连着的所有桶全部找完为止。那么为什么要有这个tophash呢？因为tophash可以快速确定key是否正确，你可以把它理解成一种缓存措施，如果前8位都不对了，后面就没有必要比较了。 源码一瞥其中红色的字标出的地方说明了上面的关键点，最后有关key和value具体的存放方式和取出的定位不做深究，有兴趣可以看最后的参考博客。 PUT其实当你知道了如何GET，那么PUT就没有什么难度了，因为本质是一样的。PUT的时候一样的方式去定位key的位置： 通过key的后“B”位确定是哪一个桶 通过key的前8位快速确定是否已经存在 最终确定存放位置，如果8个格子已经满了，没地方放了，那么就重新创建一个bmap作为溢出桶连接在overflow 图解这里主要图解说明一下，如果新来的key发现前面有一个格子空着（这个情况是删除造成的），就会记录这个位置，当全部扫描完成之后发现自己确实是新来的，那么就会放前面那个空着的，而不会放最后（我把这个称为紧凑原则，尽可能保证数据存放紧凑，这样下次扫描会快） 代码位置go/src/runtime/hashmap.go的mapassign函数就是map的put方法，因为代码很长这里就不多赘述了。 扩容这个就是最复杂的地方了，但是呢？Don’t worry我这里还是会省略其中某些部分，将最重要的地方拎出来。 扩容的方式 相同容量扩容 2倍容量扩容啥意思呢？第一种出现的情况是：因为map不断的put和delete，出现了很多空格，这些空格会导致bmap很长，但是中间有很多空的地方，扫描时间变长。所以第一种扩容实际是一种整理，将数据整理到前面一起。第二种呢：就是真的不够用了，扩容两倍。 扩容的条件装载因子如果你看过Java的HashMap实现，就知道有个装载因子，同样的在golang中也有，但是不一样哦。装载因子的定义是这个样子：loadFactor := count / (2^B)其中count为map中元素的个数，B就是之前个那个“B”翻译一下就是装载因子 = （map中元素的个数）/（map当前桶的个数） 扩容条件1装载因子 &gt; 6.5（这个值是源码中写的）其实意思就是，桶只有那么几个，但是元素很多，证明有很多溢出桶的存在（可以想成链表拉的太长了），那么扫描速度会很慢，就要扩容。 扩容条件2overflow 的 bucket 数量过多：当 B 小于 15，如果 overflow 的 bucket 数量超过 2^B ；当 B &gt;= 15，如果 overflow 的 bucket 数量超过 2^15 。其实意思就是，可能有一个单独的一条链拉的很长，溢出桶太多了，说白了就是，加入的key不巧，后B位都一样，一直落在同一个桶里面，这个桶一直放，虽然装载因子不高，但是扫描速度就很慢。 扩容条件3当前不能正在扩容 图解这张图表示的就是相同容量的扩容，实际上就是一种整理，将分散的数据集合到一起，提高扫描效率。（上面表示扩容之前，下面表示扩容之后） 这张图表示的是就是2倍的扩容（上面表示扩容之前，下面表示扩容之后），如果有两个key后三位分别是001和101，当B=2时，只有4个桶，只看最后两位，这两个key后两位都是01所以在一个桶里面；扩容之后B=3，就会有8个桶，看后面三位，于是它们就分到了不同的桶里面。 大话下面说一些扩容时的细节： 扩容不是一次性完成的，还记的我们hmap一开始有一个oldbuckets吗？是先将老数据存到这个里面 每次搬运1到2个bucket，当插入或修改、删除key触发 扩容之后肯定会影响到get和put，遍历的时候肯定会先从oldbuckets拿，put肯定也要考虑是否要放到新产生的桶里面去 源码一瞥扩容的三个条件，看到了吗？这个地方在mapassign方法中。 这里可以看到，注释也写的很清楚，如果是加载因子超出了，那么就2倍扩容，如果不是那么就是因为太多溢出桶了，sameSizeGrow表示就是相同容量扩容 evacuate是搬运方法，这边可以看到，每次搬运是1到2个 evacuate实在是太长了，也非常复杂，但是情况就是图上描述的那样，有兴趣的可以详细去看，这里不截图说明了。 总结和小问题至此你应该对于golang中的map有一个基本的认识了，你还可以去看看删除，你还可以去看看遍历等等，相信有了上面的基本认识那么应该不会难到你。下面有几个小问题： 是否线程安全？否，而且并发操作会抛出异常。 源码位置：src/runtime/hashmap.go 每次遍历map顺序是否一致？不一致，每次遍历会随机个数，通过随机数来决定从哪个元素开始。 写的仓促，难免疏漏，有问题的地方还请批评指正。 参考资料如果你希望看到源码的各种细节讲解，下面这几篇是我学习的时候看的，供你参考，希望对你有帮助https://github.com/qcrao/Go-Questions/tree/master/maphttps://github.com/cch123/golang-notes/blob/master/map.mdhttps://draveness.me/golang-hashmaphttps://lukechampine.com/hackmap.html]]></content>
      <categories>
        <category>golang源码解析</category>
      </categories>
      <tags>
        <tag>hashmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang 读写锁RWMutex 互斥锁Mutex 源码详解]]></title>
    <url>%2F2019%2F06%2F01%2Fgolang%2Fsource-code%2Frwmutex-mutex-source-code-review%2F</url>
    <content type="text"><![CDATA[Golang中有两种类型的锁，Mutex （互斥锁）和RWMutex（读写锁）对于这两种锁的使用这里就不多说了，本文主要侧重于从源码的角度分析这两种锁的具体实现。 引子问题我一般喜欢带着问题去看源码。那么对于读写锁，你是否有这样的问题，为什么可以有多个读锁？有没有可能出现有协程一直无法获取到写锁的情况？带着你的疑问来往下看看，具体这个锁是如何实现的。 如果你自己想看，我给出阅读的一个思路，可以先看读写锁，因为读写锁的实现依赖于互斥锁，并且读写锁比较简单一些，然后整理思路之后再去想一下实际的应用场景，然后再去看互斥锁。 下面我就会按照这个思路一步步往下走。 基础知识点 知识点1：信号量信号量是 Edsger Dijkstra 发明的数据结构（没错就是那个最短路径算法那个牛人），在解决多种同步问题时很有用。其本质是一个整数，并关联两个操作： 申请acquire（也称为 wait、decrement 或 P 操作）释放release（也称 signal、increment 或 V 操作） acquire操作将信号量减 1，如果结果值为负则线程阻塞，且直到其他线程进行了信号量累加为正数才能恢复。如结果为正数，线程则继续执行。release操作将信号量加 1，如存在被阻塞的线程，此时他们中的一个线程将解除阻塞。 知识点2：锁的定义在goalng中如果实现了Lock和Unlock方法，那么它就可以被称为锁。 知识点3：锁的自旋：（详见百度） 知识点4：cas算法：（最好有所了解，不知道问题也不大） 读写锁RWMutex首先我们来看看RWMutex大体结构看到结构发现读写锁内部包含了一个w Mutex互斥锁注释也很明确，这个锁的目的就是控制多个写入操作的并发执行writerSem是写入操作的信号量readerSem是读操作的信号量readerCount是当前读操作的个数readerWait当前写入操作需要等待读操作解锁的个数这几个现在看不懂没关系，后面等用到了你再回来看就好了。 然后我们看看方法一共有5个方法，看起来就不复杂，我们一个个来看。 这个最简单，就是返回一个locker对象没啥好说的 问题的关键就在于锁和解锁的几个方法，因为我已经看过，所以推荐这几个方法的阅读顺序是RLock Lock RUnlock Unlock RLock（获取读锁）先不看竞态检测的部分，先重点看红色框中的部分可以看到，其实很简单，每当有协程需要获取读锁的时候，就将readerCount + 1但是需要注意的是，这里有一个条件，当readerCount + 1之后的值 &lt; 0的时候，那么将会调用runtime_Semacquire方法这个方法是一个runtime的方法，会一直等待传入的s出现&gt;0的时候然后我们可以记得，这里有这样一个情况，当出先readerCount + 1为负数的情况那么就会被等待，看注释我们可以猜到，是当有写入操作出现的时候，那么读操作就会被等待。 Lock（获取写锁）写锁稍微复杂一些，但是样子也差不多，我们还是先来看红色框中的部分。首先操作最前面说的互斥锁，目的就是处理多个写锁并发的情况，因为我们知道写锁只有一把。这里不需要深入互斥锁，只需要知道，互斥锁只有一个人能拿到，所以写锁只有一个人能拿到。 然后重点来了，这里的这个操作细细体会一下，atomic.AddInt32(&amp;rw.readerCount, -rwmutexMaxReaders)是将当前的readerCount减去一个非常大的值rwmutexMaxReaders为1 &lt;&lt; 30大概是1073741823这么大吧 所以我们可以从源码中看出，readerCount由于每有一个协程获取读锁就+1，一直都是正数，而当有写锁过来的时候，就瞬间减为很大的负数。然后做完上面的操作以后的r其实就是原来的readerCount。后面进行判断，如果原来的readerCount不为0（原来有协程已经获取到了读锁）并且将readerWait加上readerCount（表示需要等待readerCount这么多个读锁进行解锁），如果满足上述条件证明原来有读锁，所以暂时没有办法获取到写锁，所以调用runtime_Semacquire进行等待，等待的信号量为writerSem RUnlock（释放读锁）如果是我们来写的话，可能就是将之前+1的readerCount，-1就完事了，但是其实还有一些操作需要注意。如果-1之后+1==0是啥情况？没错就是我们常见的，新手程序员，没有获取读锁就想去释放读锁，于是异常了。当然+1之后刚好是rwmutexMaxReaders，就证获取了写锁而去释放了读锁，导致异常。除去异常情况，剩下的就是r还是&lt;0的情况，那么证明确实有协程正在想要获取写锁，那么就需要操作我们前面看到的readerWait，当readerWait减到0的时候就证明没有人正在持有写锁了，就通过信号量writerSem的变化告知刚才等待的协程（想要获取写锁的协程）：你可以进行获取了。 到这里你可以把思路大致串起来了，然后懂了再往下看。 Unlock（释放写锁）写锁释放需要恢复readerCount，还记得上锁的时候减了一个很大的数，这个时候要加回来了。当然加完之后如果&gt;=rwmutexMaxReaders本身，那么还是新手程序员的问题，当没有获取写锁的时候就开始想着释放写锁了。然后for循环就是为了通知所有在我们RLock方法中看到的，当有因为持有写锁所以等待的那些协程，通过信号量readerSem告诉他们可以动了。最后别忘记还有一个互斥锁需要释放，让别的协程也可以开始抢写锁了。 至此，读写锁的分析基本上告一段落了。针对于其中关于竞态分析的代码，有兴趣的小伙伴可以去了解一下。 互斥锁Mutex互斥锁比读写锁复杂，但是好在golang给的注释很详细，所以也不困难（注释真的很重要）。我们先来看看里面的一段注释：很长的一段英文，我用英语四级的翻译能力给你翻译一下，可以将就看看，如果可以建议你仔细看英文看懂它，因为这对于后面的源码阅读非常重要。///这个互斥锁是公平锁 互斥锁有两种操作模式：正常模式和饥饿模式。在正常模式下等待获取锁的goroutine会以一个先进先出的方式进行排队，但是被唤醒的等待者并不能代表它已经拥有了这个mutex锁，它需要与新到达的goroutine争夺mutex锁。新来的goroutine有一个优势 —— 他们已经在CPU上运行了并且他们，所以抢到的可能性大一些，所以一个被唤醒的等待者有很大可能抢不过。在这样的情况下，被唤醒的等待者在队列的头部。如果一个等待者抢锁超过1ms失败了，就会切换为饥饿模式。 在饥饿模式下，mutex锁会直接由解锁的goroutine交给队列头部的等待者。新来的goroutine不能尝试去获取锁，即使可能根本就没goroutine在持有锁，并且不能尝试自旋。取而代之的是他们只能排到队伍尾巴上乖乖等着。 如果一个等待者获取到了锁，并且遇到了下面两种情况之一，就恢复成正常工作模式。情况1：它是最后一个队列中的等待者。情况2：它等待的时间小于1ms 正常模式下，即使有很多阻塞的等待者，有更好的表现，因为一轮能多次获得锁的机会。饥饿模式是为了避免那些一直在队尾的倒霉蛋。/// 我的话简单总结就是，互斥锁有两种工作模式，竞争模式和队列模式，竞争就是大家一起抢，队列就是老老实实排队，这两种工作模式会通过一些情况进行切换。 首先还是来看看大体结构可以看到，相对读写锁，结构上面很简单，只有两个值，但是千万不要小瞧它，减少了字段就增加了理解难度。state：将一个32位整数拆分为：当前阻塞的goroutine数(29位)饥饿状态(1位，0为正常模式；1为饥饿模式)唤醒状态(1位，0未唤醒；1已唤醒)锁状态(1位，0可用；1占用) sema：信号量 方法也很简单，就是Lock和Unlock两个方法，一个上锁，一个解锁，没啥好说的。 一个方法我们先来看一个的要用到的方法 func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool)这个函数，会先判断参数addr指向的被操作值与参数old的值是否相等，如果相等会将参数new替换参数addr所指向的值，不然的话就啥也不做。需要特别说明的是，这个方法并不会阻塞。 几个常量这是定义的几个常量，我们在一开始的注释周围可以看到，后面需要用到，暂时记住它们的初始值就好。 mutexLocked = 1 &lt;&lt; iota // 1左移0位，是1，二进制是1，（1表示已经上锁）mutexWoken // 1左移1位，是2，二进制是10mutexStarving // 1左移2位，是4，二进制是100mutexWaiterShift = iota // 就是3， 二进制是11 starvationThresholdNs = 1e6 // 这个就是我们一开始在注释里面看到的1ms，一定超过这个门限值就会更换模式 Lock获取锁因为Lock方法比较长，所以我切分一段段看，需要完整的请自己翻看源码。要注意的一点是，一定要时刻记住，Lock方法是做什么的，很简单，就是要抢锁。看不懂的时候想想这个目标。第一步，判断state状态是否为0，如果为0，证明没有协程持有锁，那么就很简单了，直接获取到锁，将mutexLocked（为1）赋值到state就可以了。 看后面的方法时，告诉需要告诉你们一个小技巧，当遇到这种位操作很多的情况，有两个方法挺好用，对于你看源码会有帮助：第一个是将所有定值先计算，然后判断非定值的情况；第二个是将所有的计算写下来，自己用笔去计算，不要执着于打字。 然后我们以下面这个段举例：首先，看注释应该能明白这一段大致意思是，如果不是饥饿模式，就会进行自旋操作，然后不断循环。 然后根据上面的技巧，old&amp;(mutexLocked|mutexStarving) == mutexLocked（下面均为二进制）mutexLocked = 1mutexStarving = 11mutexLocked = 1这三个是定值，所以我们容易得到，满足情况的结果为，当old为xxxx0xx（二进制第三位为0）等式成立。也就是我们一开始说的，state的第三位是表示这个锁当前的模式，0为正常模式，1为饥饿模式。 那么第一个if就表示，如果当前模式为正常模式，且可以自旋，就进入if条件内部。if !awoke &amp;&amp; old&amp;mutexWoken == 0 &amp;&amp; old&gt;&gt;mutexWaiterShift != 0 &amp;&amp; 同样的分析，awoke表示是否唤醒，old&amp;mutexWoken是取第二位，0表示当前协程未被唤醒，old&gt;&gt;mutexWaiterShift表示右移3位，也就是前29位，不为0证明有协程在等待，并且尝试去对比当前m.state与取出时的old状态，尝试去唤醒自己。然后自旋，并且增加自旋次数表示iter，然后重新赋值old。再循环下一次。 （你自己理一理，确实有点绕，仔细想想就想通了就对了。） 以上是使用自旋的情况，就是canSpin的。 然后进行判断old&amp;mutexStarving == 0就是第三位为0的情况，还是所说的正常模式。new就马上拿到锁了，new |= mutexLocked，表示或1，就是第一位无论是啥都赋值为1 old&amp;(mutexLocked|mutexStarving)，也就是old &amp; 0101必须当old的1和3两个位置为1的时候才是true，也就是说当前处于饥饿模式，并且锁已经被占用的情况，那么就需要排队去。排队也很精妙，new += 1 &lt;&lt; mutexWaiterShift这边注意是先计算1 &lt;&lt; mutexWaiterShift也就是将new的前29位+1，就是表示有一个协程在等待了。 好了到这里你的位操作应该就习惯的差不多了，之后我就直接说结论，不仔细的帮你01表示了，你已经长大了，要学会自己动手了。 如果当前已经标记为饥饿模式，并且没有锁住，那么设置new为饥饿模式if starving &amp;&amp; old&amp;mutexLocked != 0 { new |= mutexStarving} 如果唤醒，需要在两种情况下重设标志if awoke { 如果唤醒标志为与awoke不相协调就panic if new&amp;mutexWoken == 0 { throw(“sync: inconsistent mutex state”) } 设置唤醒状态位0,被唤醒 new &amp;^= mutexWoken} 如果获取锁成功 old&amp;(mutexLocked|mutexStarving) == 0成立表示已经获取锁，就直接退出CAS 中间这一段我就不多解释了，就是最前面注释说的，满足什么条件转换什么模式，不多说了。然后从队列中，也就是前29位-1。需要注意其中有一个runtime_SemacquireMutex和之前看的的runtime_Semacquire是一个意思，只是多了一个参数。这个就是这个方法的注释。可以看到，就是多了个队列去排队。 如果获取锁失败，old刷新状态再次循环，继续cas UnLock释放锁 Unlock就相对简单一些，竞态分析不看。其实我们自己想也能想到，unlock就是将标识位改回来嘛。然后因为我们已经看过读写锁了，也是同样的道理，如果没有上锁就直接解锁，那肯定报错嘛。 然后如果是正常模式，如果没有等待的goroutine或goroutine已经解锁完成的情况就直接返回了。如果有等待的goroutine那就通过信号量去唤醒runtime_Semrelease（注意这里是false），同时操作一下队列-1 如果是饥饿模式就直接唤醒（注意这里是true），反正有队列嘛。 互斥锁总结其实话说回来，我们其实看起来也简单，没有冲突的情况下，能拿就拿呗，如果出现冲突了就尝试自旋解决（自旋一般都能解决）如果解决不了就通过信号量解决，同时如果正常模式就是我们说的抢占式，非公平，如果是饥饿模式，就是我们说的排队，公平，防止有一些倒霉蛋一直抢不到。 整体总结一下，看完源码我们发现，其实锁的设计并不复杂，主要设计我们要学到cas和处理读写状态的信号量通知，对于那些位操作，能看懂，学可能一时半会学不会，因为很难在一开始就设计的那么巧妙，你也体会到了只用一个变量就维护了整个体系是一种艺术。]]></content>
      <categories>
        <category>golang源码解析</category>
      </categories>
      <tags>
        <tag>RWMutex</tag>
        <tag>Mutex</tag>
      </tags>
  </entry>
</search>
